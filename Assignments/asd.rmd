---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.13.8
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

# Counterfeit detection


The task in this assignment is to detect the  counterfeit banknotes. The data set is based on [banknote authentication Data Set ](https://archive.ics.uci.edu/ml/datasets/banknote+authentication#) from UCI Machine Learning repository.  You have already used this set but this time I have removed  the first column. The set  `banknote_authentication.csv` can be found in the `data`  directory.

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as st
import scrapbook as sb
```

<!-- #region tags=["skip"] -->
You will have to install a popular plotting library `seaborn`
<!-- #endregion -->

```{python}
data = pd.read_csv('data/banknote_authentication.csv')
```

```{python}
data.head()
```

## Problem 


### A.


Perform the Quadratic Discriminant Analysis on this set. Calculate the confusion matrix, AUC score and plot the ROC curve. Please use `scrapbook` to store your results. 

```{python}
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.model_selection import  train_test_split
from sklearn.metrics import confusion_matrix, f1_score, roc_curve, roc_auc_score, ConfusionMatrixDisplay
```

```{python}
seed = 77678
train_data, test_data = train_test_split(data,test_size=0.25)
```

```{python}
train_data.iloc[:,0:3]
```

```{python}
qda_cls = QuadraticDiscriminantAnalysis(store_covariance=True)
qda_cls.fit(train_data.iloc[:,0:3], train_data.counterfeit==1)
test_predict_qda = qda_cls.predict(test_data.iloc[:,0:3])
```

```{python}
con_mat = pd.DataFrame(confusion_matrix(test_data.counterfeit==1, test_predict_qda>0.5, normalize='true'))
```

```{python}
ConfusionMatrixDisplay(confusion_matrix(test_data.counterfeit==1, test_predict_qda>0.5, normalize='true'), display_labels=qda_cls.classes_).plot()
```

```{python}
f1 = f1_score(test_data.counterfeit==1, test_predict_qda)
test_predict_proba_qda = qda_cls.predict_proba(test_data.iloc[:,0:3])[:,1]
fprsA, tprsA, thdsA = roc_curve(test_data.counterfeit==1, test_predict_proba_qda)
aucA = roc_auc_score(test_data.counterfeit==1, test_predict_proba_qda)
```

```{python}
FP = (con_mat.sum(axis=0) - np.diag(con_mat))[1]
FN = (con_mat.sum(axis=1) - np.diag(con_mat))[1]
TP = (np.diag(con_mat))[1]
TN = con_mat.values.sum() - (FP + FN + TP)
```

```{python}
tnr = TN / (FP + TN)
fpr = FP / (FP + TN)
fnr = FN / (FN + TP)
tpr = TP / (FN + TP)
precision = TP / (FP + TP)
f1 = 2 * TP / (TP + FP + FN + TP)
print(tnr, fpr, fnr, tpr, precision, f1)
```

```{python}
sb.glue('A_scores',['tnr', 'fpr', 'fnr', 'tpr', 'precision', 'f1', 'auc'], display=True)
sb.glue('A_scores_values',[tnr, fpr, fnr, tpr, precision, f1, aucA], display=True)
```

also please save the ROC plot

```{python}
fig, ax = plt.subplots(figsize=(10, 10))
ax.plot(fprsA, tprsA, label="{:s}  {:5.3f}".format("QDA", aucA));
ax.plot([0,1],[0,1]);
ax.legend()
sb.glue('A_ROC',fig, "display", display=False);
```

### B.


Perform Gaussian Mixture Discriminant Analysis on this set as described in the `gaussian_mixture_model_EM_algorithm` notebook. Use two components for positives and two components for negatives. Calculate the confusion matrix, AUC score and plot the ROC curve. 

```{python}
from sklearn.mixture import GaussianMixture
```

```{python}
bank0_cmp = GaussianMixture(n_components=2, max_iter=100, tol=0.0001)
bank1_cmp = GaussianMixture(n_components=2, max_iter=100, tol=0.0001)
```

```{python}
train_lbl_data = train_data.iloc[:,3]
train_data = train_data.iloc[:,0:3]
test_lbl_data = test_data.iloc[:,3]
test_data = test_data.iloc[:,0:3]
```

```{python}
bank0 = train_data[train_lbl_data==0]
bank1 = train_data[train_lbl_data==1]
```

```{python}
bank0_cmp.fit(bank0)
bank1_cmp.fit(bank1)
```

```{python}
def make_pdf(cmp):
    n_cmp = cmp.n_components
    dists = [st.multivariate_normal(cmp.means_[i], cmp.covariances_[i]) for i in range(n_cmp)]
    def pdf(x):
        p = 0.0
        for i in range(n_cmp):
            p+= cmp.weights_[i]*dists[i].pdf(x)
        return p
    return pdf
    
    
def make_predict_proba(cmp0, cmp1, pi0=0.5, pi1=.5):
    pdf0 = make_pdf(cmp0)
    pdf1 = make_pdf(cmp1)
    def p(x):
        p0=pi0*pdf0(x)
        p1=pi1*pdf1(x)
        return p1/(p1+p0)
    return p
```

```{python}
mgd_predict_proba = make_predict_proba(bank0_cmp, bank1_cmp, 0.5, 0.5)
```

```{python}
mgd_proba = mgd_predict_proba(test_data)
```

```{python}
con_mat = pd.DataFrame(confusion_matrix(test_lbl_data, mgd_proba>0.5, normalize='true'))
```

```{python}
fprsB, tprsB, thdsB = roc_curve(test_lbl_data, mgd_proba)
aucB = roc_auc_score(test_lbl_data, mgd_proba)
```

```{python}
FP = (con_mat.sum(axis=0) - np.diag(con_mat))[1]
FN = (con_mat.sum(axis=1) - np.diag(con_mat))[1]
TP = (np.diag(con_mat))[1]
TN = con_mat.values.sum() - (FP + FN + TP)
```

```{python}
tnr = TN / (FP + TN)
fpr = FP / (FP + TN)
fnr = FN / (FN + TP)
tpr = TP / (FN + TP)
precision = TP / (FP + TP)
f1 = 2 * TP / (TP + FP + FN + TP)
```

```{python}
sb.glue('B_scores',['tnr', 'fpr', 'fnr', 'tpr', 'precision', 'f1', 'auc'], display=True)
sb.glue('B_scores_values',[tnr, fpr, fnr, tpr, precision, f1, aucB], display=True)
```

also please save the ROC plot

```{python}
fig, ax = plt.subplots(figsize=(10, 10))
ax.plot(fprsA, tprsA, label="{:s}  {:5.3f}".format("QDA", aucA));
ax.plot(fprsB, tprsB, label="{:s}  {:5.3f}".format("MGD", aucB));
ax.plot([0,1],[0,1]);
ax.legend()
sb.glue('B_ROC',fig, "display", display=False);
```

### C.


Use k-fold cross validation to find the optimal number of gaussian components for each class. As before calculate the confusion matrix, AUC score and plot the ROC curve for the best classifier. Assume that maximal number of components in each class is 12.  


__Hint__ use the `StratifiedKFold` function from scikit-learn library to generate folds. 

```{python}
def evaluate(nc0, nc1,X,y, X_valid, y_valid):
    bank0_cmp = GaussianMixture(n_components=nc0, max_iter=100, tol=0.0001) 
    bank1_cmp = GaussianMixture(n_components=nc1, max_iter=100, tol=0.0001) 
    bank0 = X[y==0]
    bank1 = X[y==1]
    bank0_cmp.fit(bank0)
    bank1_cmp.fit(bank1)
    
    gmda =  make_predict_proba(bank0_cmp, bank1_cmp, 0.5, 0.5)
    proba = gmda(X_valid)
    
    return f1_score(y_valid, proba>0.5), bank0_cmp, bank1_cmp
```

```{python}
from sklearn.model_selection import KFold
```

```{python}
folder = KFold(5,shuffle=True, random_state=67544)
```

```{python}
n_cmp_pos=None
n_cmp_neg=None
best_f1_score=None
best_pos_c = None
best_neg_c = None
best_f1_after_n = 0
for pos_c in range(2, 13):
    for neg_c in range(2, 13):
        f1=0
        for train_i, test_i in folder.split(train_data, train_lbl_data):
            best_f1_score, n_cmp_neg, n_cmp_pos = evaluate(neg_c,pos_c,train_data.iloc[train_i], train_lbl_data.iloc[train_i], train_data.iloc[test_i], train_lbl_data.iloc[test_i])
            f1+=best_f1_score
        if best_f1_after_n < f1/folder.get_n_splits():
            best_pos_c = pos_c
            best_neg_c = neg_c
            best_f1_after_n = f1/folder.get_n_splits()
print(f"Best f1 {best_f1_score}, best pos c {best_pos_c}, best neg c {best_neg_c}")
```

```{python}
#  store the results of the best fit 
sb.glue("C_n_cmp",['n_cmp_pos', 'n_cmp_neg', 'best_f1_score'])
```

```{python}
mgd_predict_proba2 = make_predict_proba(n_cmp_neg, n_cmp_pos, 0.5, 0.5)
```

```{python}
mgd_proba2 = mgd_predict_proba(test_data)
```

```{python}
con_mat = pd.DataFrame(confusion_matrix(test_lbl_data, mgd_proba2>0.5, normalize='true'))
```

```{python}
fprsC, tprsC, thdsC = roc_curve(test_lbl_data, mgd_proba2)
aucC = roc_auc_score(test_lbl_data, mgd_proba2)
```

```{python}
FP = (con_mat.sum(axis=0) - np.diag(con_mat))[1]
FN = (con_mat.sum(axis=1) - np.diag(con_mat))[1]
TP = (np.diag(con_mat))[1]
TN = con_mat.values.sum() - (FP + FN + TP)
```

```{python}
tnr = TN / (FP + TN)
fpr = FP / (FP + TN)
fnr = FN / (FN + TP)
tpr = TP / (FN + TP)
precision = TP / (FP + TP)
f1 = 2 * TP / (TP + FP + FN + TP)
```

Store the results for the best estimator

```{python}
sb.glue('C_scores',['tnr', 'fpr', 'fnr', 'tpr', 'precision', 'f1', 'auc'], display=True)
sb.glue('C_scores_values',[tnr, fpr, fnr, tpr, precision, f1, aucC], display=True)
```

also please save the ROC plot

```{python}
fig, ax = plt.subplots(figsize=(10, 10))
ax.plot(fprsA, tprsA, label="{:s}  {:5.3f}".format("QDA", aucA));
ax.plot(fprsB, tprsB, label="{:s}  {:5.3f}".format("MGD", aucB));
ax.plot(fprsC, tprsC, label="{:s}  {:5.3f}".format("Kfold_MGD", aucC));
ax.plot([0,1],[0,1]);
ax.legend()
sb.glue('C_ROC',fig, "display", display=False);
```

## D.  


Assume that 1% of all the customers in your store try to pay with a counterfeit 100PLN bill. If you accept the counterfeit bill you loose 100PLN. If you reject a valid bill,  you may loose the purchase, you estimate this loss as 15PLN on average. For each of the three classifiers find the threshold that minimises your losses and calculates the minimum loss for each classifier. Show the optimal classifiers points on the ROC curves.

```{python}
def find_min(fprs, tprs, thds):
    min_loss = 10**20
    min_loss_indx = 0
    for i, fpr in enumerate(fprs):
        loss = 99*fpr*15 + 100 * (1-tprs[i])
        if min_loss > loss:
            min_loss = loss
            min_loss_indx = i
    return fprs[min_loss_indx], tprs[min_loss_indx], thds[min_loss_indx], min_loss
```

```{python}
min_fprA, min_tprA, min_thdsA, min_lossA = find_min(fprsA, tprsA, thdsA)
```

```{python}
sb.glue('D_A_scores',['tnr', 'fpr', 'fnr', 'tpr', 'auc', 'min_loss', 'threshold'], display=True)
sb.glue('D_A_scores',[1-min_tprA, min_fprA, 1-min_tprA, min_tprA, aucA, min_lossA, min_thdsA], display=True)
```

```{python}
min_fprB, min_tprB, min_thdsB, min_lossB = find_min(fprsB, tprsB, thdsB)
```

```{python}
sb.glue('D_B_scores',['tnr', 'fpr', 'fnr', 'tpr', 'auc', 'min_loss', 'threshold'], display=True)
sb.glue('D_B_scores',[1-min_tprB, min_fprB, 1-min_tprB, min_tprB, aucB, min_lossB, min_thdsB], display=True)
```

```{python}
min_fprC, min_tprC, min_thdsC, min_lossC = find_min(fprsC, tprsC, thdsC)
```

```{python}
sb.glue('D_C_scores',['tnr', 'fpr', 'fnr', 'tpr', 'auc', 'min_loss', 'threshold'], display=True)
sb.glue('D_C_scores',[1-min_tprC, min_fprC, 1-min_tprC, min_tprC, aucC, min_lossC, min_thdsC], display=True)
```

also please save the ROC plot

```{python}
fig, ax = plt.subplots(figsize=(10, 10))
ax.plot(fprsA, tprsA, label="{:s}  {:5.3f}".format("QDA", aucA));
ax.plot(fprsB, tprsB, label="{:s}  {:5.3f}".format("MGD", aucB));
ax.plot(fprsC, tprsC, label="{:s}  {:5.3f}".format("Kfold_MGD", aucC));
ax.plot([0,1],[0,1]);
ax.scatter(min_fprA, min_tprA, color="black");
ax.scatter(min_fprB, min_tprB, color="black");
ax.scatter(min_fprC, min_tprC, color="black");
ax.legend()
sb.glue('D_ROC',fig, "display", display=False);
```